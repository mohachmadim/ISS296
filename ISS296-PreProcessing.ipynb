{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.preprocessing.image import array_to_img\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os \n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from PIL import Image \n",
    "from numpy import asarray\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = r\"C:\\Users\\rassa\\Documents\\Machine Learning A-Z  Udemy\\Arabic Handwritten Characters Dataset\"\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# using opencv library's imread\n",
    "cv2image = cv2.imread(DATADIR+ r\"\\Train Images 13440x32x32\\train\\id_1_label_1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(cv2image)\n",
    "cv2image.shape\n",
    "cv2.imshow('cv2image', cv2image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using asarray from numpy\n",
    "img2 = Image.open(DATADIR+ r\"\\Train Images 13440x32x32\\train\\id_1_label_1.png\")\n",
    "\n",
    "asarrayimage = asarray(img2)\n",
    "print(asarrayimage)\n",
    "\n",
    "plt.imshow(asarrayimage)\n",
    "cv2.imshow('asarray', asarrayimage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "asarrayimage.shape\n",
    "asarrayimage.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras image _to_array\n",
    "imgK = load_img(DATADIR+ r\"\\Train Images 13440x32x32\\train\\id_1_label_1.png\")\n",
    "imgKdata = img_to_array(imgK)\n",
    "print(imgKdata)\n",
    "plt.imshow(imgKdata)\n",
    "imgKdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we try to get the image from the csv file\n",
    "\n",
    "csvarray = pd.read_csv(DATADIR + r\"\\csvTrainImages 13440x1024.csv\", nrows = 1, header= None)\n",
    "\n",
    "csvarray.shape\n",
    "csvarray= csvarray.iloc[:,:].values.astype('uint8')\n",
    "csvarray.shape\n",
    "csvarray = csvarray.reshape([32, 32, 1])\n",
    "csvarray.shape\n",
    "\n",
    "print(csvarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasimgfromcsv = array_to_img(csvarray)\n",
    "plt.imshow(kerasimgfromcsv)\n",
    "cv2.imshow('example', csvarray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no dice, still dont know how they did it...\n",
    "# let's just convert the pictures our own way...\n",
    "\n",
    "path = DATADIR+ r\"\\Train Images 13440x32x32\\train\"\n",
    "\n",
    "#returns a list containing all the directories in path (names of the images)\n",
    "imgFileNameList = os.listdir(path)\n",
    "\n",
    "\n",
    "print(imgFileNameList[0])\n",
    "imageIdTest = imgFileNameList[0].split('_')[1]\n",
    "print(imageIdTest)\n",
    "\n",
    "#it work! so now we use this label as our sorting criteria\n",
    "def getImgId(imgName):\n",
    "    return int(imgName.split('_')[1])\n",
    "\n",
    "imgFileNameList.sort(key=getImgId)\n",
    "print(imgFileNameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = cv2.imread(os.path.join(path,imgFileNameList[0]) ,cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('test',img_array)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "img_array.shape\n",
    "img_array.reshape([32,32,1])\n",
    "\n",
    "# it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we make our new train_data\n",
    "train_data = []\n",
    "\n",
    "for img in tqdm(imgFileNameList):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                train_data.append([img_array])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look at the shape of our array\n",
    "train_data = np.asarray(train_data)\n",
    "print(train_data.shape)\n",
    "train_data = train_data.reshape([-1, 32, 32, 1])\n",
    "print(train_data.shape)\n",
    "np.set_printoptions(threshold=1000)\n",
    "print(train_data)\n",
    "#looks the same as train_data from our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 13440/13440 [00:02<00:00, 4746.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3360/3360 [00:00<00:00, 4798.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13440, 32, 32, 1)\n",
      "(13440, 32, 32, 1)\n",
      "[[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's put allwe need in one cell and test!\n",
    "DATADIR = r\"C:\\Users\\rassa\\Documents\\Machine Learning A-Z  Udemy\\Arabic Handwritten Characters Dataset\"\n",
    "train_data = []\n",
    "test_data = []\n",
    "trainPath = DATADIR + r\"\\Train Images 13440x32x32\\train\"\n",
    "testPath  = DATADIR + r\"\\Test Images 3360x32x32\\test\"\n",
    "\n",
    "def getImgId(imgName):\n",
    "    return int(imgName.split('_')[1])\n",
    "\n",
    "def makeData(data, directory, sortingCriteria):\n",
    "    imgFileNameList = os.listdir(directory)     #get list of directories in path (ie. list of image names)\n",
    "    imgFileNameList.sort(key = sortingCriteria) #sort list based on key\n",
    "    \n",
    "    for img in tqdm(imgFileNameList):  # iterate over the sorted list\n",
    "                try:\n",
    "                    img_array = cv2.imread(os.path.join(directory, img) ,cv2.IMREAD_GRAYSCALE)  # convert image to array\n",
    "                    data.append([img_array])  # add this to our data\n",
    "                except Exception as e:  # just in case there is a mistake.\n",
    "                    pass\n",
    "\n",
    "makeData(train_data, trainPath, getImgId)\n",
    "makeData(test_data, testPath, getImgId)\n",
    "\n",
    "# convert to ndarray and reshape\n",
    "train_data = np.asarray(train_data).reshape([-1, 32, 32, 1])\n",
    "test_data = np.asarray(test_data).reshape([-1, 32, 32, 1])\n",
    "print(train_data.shape)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3360, 32, 32, 1)\n",
      "(32, 32, 1)\n",
      "[[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(train_data[0].shape)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]\n",
      "\n",
      "\n",
      " [[[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]\n",
      "\n",
      "  [[0]\n",
      "   [0]\n",
      "   [0]\n",
      "   ...\n",
      "   [0]\n",
      "   [0]\n",
      "   [0]]]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more testing\n",
    "cv2.imshow('test', train_data[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.0\n",
      " Basic Linear Transforms \n",
      "-------------------------\n",
      "* Enter the alpha value [1.0-3.0]: 3.0\n",
      "* Enter the beta value [0-100]: 0\n"
     ]
    }
   ],
   "source": [
    "# Now let's try to work with a sample to test\n",
    "\n",
    "# Read image given by user\n",
    "#parser = argparse.ArgumentParser(description='Code for Changing the contrast and brightness of an image! tutorial.')\n",
    "#parser.add_argument('9alb-Ba2-0.png', help='C:\\Users\\rassa\\Desktop\\Desktop2.0\\CNN', default='9alb-Ba2-0.png')\n",
    "#args = parser.parse_args()\n",
    "#r\"C:\\Users\\rassa\\Desktop\\Desktop2.0\\CNN\\9alb-Ba2-0.png\") #\n",
    "image = cv2.imread(r\"C:\\Users\\rassa\\Desktop\\Desktop2.0\\CNN\\9alb-Ba2-0.png\") #(cv.samples.findFile(args.input))\n",
    "#removethe three dimensions and turn image to gray scale\n",
    "im_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#binarize the image using Otsu method to get the threshold, binarize to black and white(ie. 255)\n",
    "th, im_gray_th_otsu = cv2.threshold(im_gray, 128, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "#print the threshold because I'm curious\n",
    "print(th)\n",
    "new_image = np.zeros(im_gray_th_otsu.shape, im_gray_th_otsu.dtype)\n",
    "alpha = 1.0 # Simple contrast control\n",
    "beta = 0    # Simple brightness control\n",
    "# Initialize values\n",
    "try:\n",
    "    alpha = float(input('* Enter the alpha value [1.0-3.0]: '))\n",
    "    beta = int(input('* Enter the beta value [0-100]: '))\n",
    "except ValueError:\n",
    "    print('Error, not a number')\n",
    "# Do the operation new_image(i,j) = alpha*image(i,j) + beta\n",
    "# Instead of these 'for' loops we could have used simply:\n",
    "# new_image = cv.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "# but we wanted to show you how to access the pixels :)\n",
    "for y in range(im_gray_th_otsu.shape[0]):\n",
    "    for x in range(im_gray_th_otsu.shape[1]):\n",
    "        # the clip makes sure that the new values of the pixel are between 0 and 255\n",
    "        new_image[y,x] = np.clip(alpha*im_gray_th_otsu[y,x] + beta, 0, 255)\n",
    "\n",
    "#Show the images so we can compare them\n",
    "cv2.imshow('New Image', new_image)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Binarized image', im_gray_th_otsu)\n",
    "# Wait until user press some key\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Enter the alpha value [1.0-3.0]: 1.5\n",
      "* Enter the beta value [0-100]: 0\n",
      "253.0\n"
     ]
    }
   ],
   "source": [
    "# Now let's try enhacing the edges first\n",
    "\n",
    "# Read image given by user\n",
    "image = cv2.imread(r\"C:\\Users\\rassa\\Desktop\\Desktop2.0\\CNN\\9alb-Ba2-0.png\") #(cv.samples.findFile(args.input))\n",
    "kernel0 = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "\n",
    "\n",
    "edge_enhance_img0 = cv2.filter2D(image, -1, kernel0)\n",
    "\n",
    "\n",
    "contrast_img = np.zeros(edge_enhance_img0.shape, edge_enhance_img0.dtype)\n",
    "\n",
    "alpha = 1.0 # Simple contrast control\n",
    "beta = 0    # Simple brightness control\n",
    "\n",
    "# Initialize values\n",
    "try:\n",
    "    alpha = float(input('* Enter the alpha value [1.0-3.0]: '))\n",
    "    beta = int(input('* Enter the beta value [0-100]: '))\n",
    "except ValueError:\n",
    "    print('Error, not a number')\n",
    "    \n",
    "# Do the operation new_image(i,j) = alpha*image(i,j) + beta\n",
    "# Instead of these 'for' loops we could have used simply:\n",
    "# new_image = cv.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "# but we wanted to show you how to access the pixels :)\n",
    "for y in range(edge_enhance_img0.shape[0]):\n",
    "    for x in range(edge_enhance_img0.shape[1]):\n",
    "        for c in range(edge_enhance_img0.shape[2]):\n",
    "            # the clip makes sure that the new values of the pixel are between 0 and 255\n",
    "            contrast_img[y,x,c] = np.clip(alpha*edge_enhance_img0[y,x,c] + beta, 0, 255)\n",
    "        \n",
    "#removethe three dimensions and turn image to gray scale\n",
    "im_gray = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "#binarize the image using Otsu method to get the threshold, binarize to black and white(ie. 255)\n",
    "th, im_gray_th_otsu = cv2.threshold(im_gray, 128, 255, cv2.THRESH_TRIANGLE)\n",
    "\n",
    "resized = cv2.resize(im_gray_th_otsu, (28,28), interpolation = cv2.INTER_AREA)\n",
    "#print the threshold because I'm curious\n",
    "print(th)\n",
    "\n",
    "#Show the images so we can compare them\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Edge Enhaced0 image', edge_enhance_img0)\n",
    "cv2.imshow('Contrast image', contrast_img)\n",
    "cv2.imshow('New Image', im_gray_th_otsu)\n",
    "cv2.imshow('resized Image', resized)\n",
    "\n",
    "\n",
    "# Wait until user press some key\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Enter the alpha value [1.0-3.0]: 1.5\n",
      "* Enter the beta value [0-100]: 0\n",
      "230.0\n"
     ]
    }
   ],
   "source": [
    "# Now let's doing the contrast first\n",
    "\n",
    "# Read image given by user\n",
    "image = cv2.imread(r\"C:\\Users\\rassa\\Desktop\\Desktop2.0\\CNN\\9alb-Ba2-0.png\") #(cv.samples.findFile(args.input))\n",
    "\n",
    "contrast_img = np.zeros(image.shape, image.dtype)\n",
    "\n",
    "alpha = 1.0 # Simple contrast control\n",
    "beta = 0    # Simple brightness control\n",
    "\n",
    "# Initialize values\n",
    "try:\n",
    "    alpha = float(input('* Enter the alpha value [1.0-3.0]: '))\n",
    "    beta = int(input('* Enter the beta value [0-100]: '))\n",
    "except ValueError:\n",
    "    print('Error, not a number')\n",
    "    \n",
    "# Do the operation new_image(i,j) = alpha*image(i,j) + beta\n",
    "# Instead of these 'for' loops we could have used simply:\n",
    "# new_image = cv.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "# but we wanted to show you how to access the pixels :)\n",
    "for y in range(image.shape[0]):\n",
    "    for x in range(image.shape[1]):\n",
    "        for c in range(image.shape[2]):\n",
    "            # the clip makes sure that the new values of the pixel are between 0 and 255\n",
    "            contrast_img[y,x,c] = np.clip(alpha*image[y,x,c] + beta, 0, 255)\n",
    "        \n",
    "#removethe three dimensions and turn image to gray scale\n",
    "im_gray = cv2.cvtColor(contrast_img, cv2.COLOR_BGR2GRAY)\n",
    "#binarize the image using Otsu method to get the threshold, binarize to black and white(ie. 255)\n",
    "th, im_gray_th_otsu = cv2.threshold(im_gray, 128, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "resized = cv2.resize(im_gray_th_otsu, (28,28), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "#print the threshold because I'm curious\n",
    "print(th)\n",
    "\n",
    "final_img = np.zeros(resized.shape, resized.dtype)\n",
    "for y in range(resized.shape[0]):\n",
    "    for x in range(resized.shape[1]):\n",
    "        if resized[y,x] < 125:     \n",
    "            final_img[y,x] = 255\n",
    "        else :\n",
    "            final_img[y,x] = 0\n",
    "\n",
    "#Show the images so we can compare them\n",
    "cv2.imshow('New Image', im_gray_th_otsu)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Contrast image', contrast_img)\n",
    "cv2.imshow('resized Image', resized)\n",
    "cv2.imshow('final Image', final_img)\n",
    "\n",
    "# Wait until user press some key\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#this one gives the best results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
