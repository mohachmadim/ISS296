{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "import tflearn.data_utils as du\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DIRECTORY = r\"C:\\Users\\rassa\\Documents\\Machine Learning A-Z  Udemy\\Arabic Handwritten Characters Dataset\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.919  0.920  \\\n",
      "0     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "3354  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3355  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3356  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3357  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3358  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "      0.921  0.922  0.923  0.924  0.925  0.926  0.927  0.928  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3354      0      0      0      0      0      0      0      0  \n",
      "3355      0      0      0      0      0      0      0      0  \n",
      "3356      0      0      0      0      0      0      0      0  \n",
      "3357      0      0      0      0      0      0      0      0  \n",
      "3358      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[3359 rows x 1024 columns]\n",
      "      0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
      "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "3355     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3356     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3357     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3358     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3359     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "      1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
      "0        0     0     0     0     0     0     0     0     0  \n",
      "1        0     0     0     0     0     0     0     0     0  \n",
      "2        0     0     0     0     0     0     0     0     0  \n",
      "3        0     0     0     0     0     0     0     0     0  \n",
      "4        0     0     0     0     0     0     0     0     0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3355     0     0     0     0     0     0     0     0     0  \n",
      "3356     0     0     0     0     0     0     0     0     0  \n",
      "3357     0     0     0     0     0     0     0     0     0  \n",
      "3358     0     0     0     0     0     0     0     0     0  \n",
      "3359     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[3360 rows x 1024 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "#header = 0 because\n",
    "#this creates a pandas dataframe (basically a table)\n",
    "train_data = pd.read_csv(DIRECTORY +  '/csvTrainImages 13440x1024.csv', header = None)\n",
    "train_label = pd.read_csv(DIRECTORY + '/csvTrainLabel 13440x1.csv', header = None)\n",
    "\n",
    "test_label = pd.read_csv(DIRECTORY +  '/csvTestLabel 3360x1.csv', header = None)\n",
    "\n",
    "\n",
    "#what happens if we take off header = none ?\n",
    "#Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no \n",
    "#names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, \n",
    "#if column names are passed explicitly then the behavior is identical to header=None.\n",
    "#notice if we do this we have one row less\n",
    "test_data = pd.read_csv(DIRECTORY +   '/csvTestImages 3360x1024.csv')\n",
    "print(test_data)\n",
    "\n",
    "test_data = pd.read_csv(DIRECTORY +   '/csvTestImages 3360x1024.csv', header = None)\n",
    "print(test_data)\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.iloc[:,:].values.astype('float32')\n",
    "train_label = train_label.iloc[:,:].values.astype('int32')-1\n",
    "test_data = test_data.iloc[:,:].values.astype('float32')\n",
    "test_label = test_label.iloc[:,:].values.astype('int32')-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = du.to_categorical(train_label,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/255\n",
    "test_data = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape([-1, 32, 32, 1])\n",
    "test_data = test_data.reshape([-1, 32, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, mean1 = du.featurewise_zero_center(train_data)\n",
    "test_data, mean2 = du.featurewise_zero_center(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recognizer = Sequential()\n",
    "#for any kind of deep learning we use the sequential model in keras then \n",
    "#add layers to it\n",
    "recognizer.add(Conv2D(filters = 18, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (32,32,1)))\n",
    "#the first 2 dimensional convolusion layer will have 32 filters. filters or kernels are \n",
    "#what we use to extract features. in this case they are of size 5x5 (kernel size)\n",
    "#in the first layer it is necessary to specify the shape so for our case its a\n",
    "#32x32 pixel image and since it's black and white then it has only one dimension\n",
    "#if it was colored then we would have (32,32,3)\n",
    "#activation='relu' this is rectified linear unit. the output filters or convolced layers\n",
    "#might contain some negative values so we apply the rectifier function (or other functions)\n",
    "\n",
    "recognizer.add(MaxPool2D(pool_size=(2,2), strides=(1,1)))\n",
    "\n",
    "\n",
    "\n",
    "recognizer.add(Flatten())\n",
    "\n",
    "recognizer.add(Dense(28, input_dim = 1024, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 18)        180       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 18)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 17298)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 28)                484372    \n",
      "=================================================================\n",
      "Total params: 484,552\n",
      "Trainable params: 484,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recognizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rassa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:1240: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 - 8s - loss: 2.4378 - acc: 0.2912\n",
      "Epoch 2/30\n",
      "134/134 - 7s - loss: 1.8883 - acc: 0.4416\n",
      "Epoch 3/30\n",
      "134/134 - 7s - loss: 1.6148 - acc: 0.5235\n",
      "Epoch 4/30\n",
      "134/134 - 7s - loss: 1.4466 - acc: 0.5667\n",
      "Epoch 5/30\n",
      "134/134 - 7s - loss: 1.3257 - acc: 0.6069\n",
      "Epoch 6/30\n",
      "134/134 - 6s - loss: 1.2627 - acc: 0.6233\n",
      "Epoch 7/30\n",
      "134/134 - 6s - loss: 1.2013 - acc: 0.6394\n",
      "Epoch 8/30\n",
      "134/134 - 6s - loss: 1.1527 - acc: 0.6540\n",
      "Epoch 9/30\n",
      "134/134 - 7s - loss: 1.1163 - acc: 0.6696\n",
      "Epoch 10/30\n",
      "134/134 - 6s - loss: 1.0972 - acc: 0.6708\n",
      "Epoch 11/30\n",
      "134/134 - 7s - loss: 1.0449 - acc: 0.6835\n",
      "Epoch 12/30\n",
      "134/134 - 6s - loss: 1.0125 - acc: 0.6936\n",
      "Epoch 13/30\n",
      "134/134 - 7s - loss: 1.0057 - acc: 0.7068\n",
      "Epoch 14/30\n",
      "134/134 - 6s - loss: 0.9966 - acc: 0.7073\n",
      "Epoch 15/30\n",
      "134/134 - 6s - loss: 0.9940 - acc: 0.7049\n",
      "Epoch 16/30\n",
      "134/134 - 7s - loss: 0.9746 - acc: 0.7124\n",
      "Epoch 17/30\n",
      "134/134 - 6s - loss: 0.9492 - acc: 0.7151\n",
      "Epoch 18/30\n",
      "134/134 - 6s - loss: 0.9234 - acc: 0.7288\n",
      "Epoch 19/30\n",
      "134/134 - 6s - loss: 0.9139 - acc: 0.7290\n",
      "Epoch 20/30\n",
      "134/134 - 6s - loss: 0.9064 - acc: 0.7343\n",
      "Epoch 21/30\n",
      "134/134 - 6s - loss: 0.8842 - acc: 0.7406\n",
      "Epoch 22/30\n",
      "134/134 - 6s - loss: 0.8862 - acc: 0.7402\n",
      "Epoch 23/30\n",
      "134/134 - 6s - loss: 0.8574 - acc: 0.7457\n",
      "Epoch 24/30\n",
      "134/134 - 6s - loss: 0.8759 - acc: 0.7403\n",
      "Epoch 25/30\n",
      "134/134 - 6s - loss: 0.8492 - acc: 0.7485\n",
      "Epoch 26/30\n",
      "134/134 - 6s - loss: 0.8489 - acc: 0.7524\n",
      "Epoch 27/30\n",
      "134/134 - 6s - loss: 0.8375 - acc: 0.7541\n",
      "Epoch 28/30\n",
      "134/134 - 6s - loss: 0.8453 - acc: 0.7501\n",
      "Epoch 29/30\n",
      "134/134 - 6s - loss: 0.8253 - acc: 0.7560\n",
      "Epoch 30/30\n",
      "134/134 - 6s - loss: 0.8157 - acc: 0.7613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2449f4e9c10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.fit_generator(datagen.flow(train_data,train_label, batch_size=100),\n",
    "                             epochs = 30, verbose = 2, steps_per_epoch=train_data.shape[0] // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rassa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "predictions = recognizer.predict(test_data)\n",
    "predictions = np.argmax(predictions,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(cm[i][i] for i in range(28)) / test_label.shape[0]\n",
    "print(\"accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110   1   0   0   0   0   0   0   0   1   2   0   0   0   0   0   0   0\n",
      "    0   0   0   0   2   3   0   0   0   1]\n",
      " [  0 107   1   1   1   0   0   0   1   1   0   0   0   0   0   0   0   0\n",
      "    0   0   1   2   0   0   2   0   0   3]\n",
      " [  0   3  40  65   0   2   1   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   2   1   0   0   3   0   0   2]\n",
      " [  0   0   9 100   1   0   0   0   1   0   0   1   2   0   0   0   0   0\n",
      "    0   1   3   0   0   0   1   0   0   1]\n",
      " [  0   0   0   1 110   2   2   0   0   0   0   0   0   1   0   0   0   2\n",
      "    1   0   0   0   0   0   0   0   0   1]\n",
      " [  0   1   0   0  27  72   4   0   0   0   0   0   0   0   0   0   0   5\n",
      "    8   0   2   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0  16   3  70   0   0   0   1   0   1   0   0   0   1   2\n",
      "   24   0   2   0   0   0   0   0   0   0]\n",
      " [  0   1   1   0   0   2   0 107   3   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   2   0   2   1   0   1   0]\n",
      " [  0   0   0   0   0   0   1   5 103   0   2   0   0   0   0   0   2   0\n",
      "    0   0   1   0   0   0   2   0   2   2]\n",
      " [  0   0   0   0   1   4   1   2   0  98   7   1   0   0   0   0   0   0\n",
      "    0   0   0   0   2   0   0   0   4   0]\n",
      " [  0   0   0   0   0   1   0   0  10   4  98   0   2   0   0   0   2   0\n",
      "    1   0   0   0   0   0   0   1   1   0]\n",
      " [  0   0   2   0   2   0   0   1   0   0   0  88   2   7   2   0   1   0\n",
      "    0   0   0   4   0   0   1   1   0   9]\n",
      " [  0   0   0   5   2   0   0   0   0   0   0   0 108   0   0   0   0   0\n",
      "    0   0   3   0   0   0   0   0   0   2]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   6   0  97  11   0   3   0\n",
      "    0   0   0   0   0   1   0   0   0   1]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   9   5  99   0   2   0\n",
      "    0   0   2   1   0   0   0   0   1   0]\n",
      " [  0   1   0   1   0   0   1   0   0   1   0   0   0   0   1  39  72   1\n",
      "    0   0   0   2   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   4 113   0\n",
      "    0   0   0   0   0   0   0   1   0   1]\n",
      " [  0   0   1   0   4   4   3   0   0   0   0   1   0   0   0   0   2  85\n",
      "   19   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1   0   0   0   1   0   1   0   0   0   1   1\n",
      "  114   0   0   0   0   0   0   0   0   0]\n",
      " [  0   1   3   4   1   0   0   0   1   0   0   1   1   0   1   0   2   1\n",
      "    0  67  33   0   0   0   1   0   0   3]\n",
      " [  0   0   2   5   0   0   0   0   0   0   0   0  16   1   1   0   0   0\n",
      "    1   4  83   0   0   0   1   0   0   6]\n",
      " [  0   1   1   1   0   0   0   0   0   0   0   2   0   1   1   0   0   0\n",
      "    0   0   0 113   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0  15 100   0   2   0   0   1]\n",
      " [  2   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0\n",
      "    0   1   0   0   0 113   0   1   0   1]\n",
      " [  1   1   4   7   1   0   0   0   0   0   2   2   1   0   0   0   1   0\n",
      "    0   1   4   9   0   0  83   1   0   2]\n",
      " [  0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   1\n",
      "    0   1   0   3   0   0   0 111   2   0]\n",
      " [  0   0   0   0   2   1   0   2   0   4   0   0   0   0   0   1   0   0\n",
      "    0   3   0   4   0   0   0  10  93   0]\n",
      " [  0   0   0   1   1   0   0   0   1   0   0   0   0   0   1   0   0   0\n",
      "    0   0   3   1   0   0   1   0   0 111]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
