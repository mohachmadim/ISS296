{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "import tflearn.data_utils as du\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DIRECTORY = r\"C:\\Users\\rassa\\Documents\\Machine Learning A-Z  Udemy\\Arabic Handwritten Characters Dataset\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.919  0.920  \\\n",
      "0     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4     0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "3354  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3355  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3356  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3357  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3358  0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "      0.921  0.922  0.923  0.924  0.925  0.926  0.927  0.928  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "3354      0      0      0      0      0      0      0      0  \n",
      "3355      0      0      0      0      0      0      0      0  \n",
      "3356      0      0      0      0      0      0      0      0  \n",
      "3357      0      0      0      0      0      0      0      0  \n",
      "3358      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[3359 rows x 1024 columns]\n",
      "      0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
      "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "3355     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3356     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3357     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3358     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3359     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "      1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
      "0        0     0     0     0     0     0     0     0     0  \n",
      "1        0     0     0     0     0     0     0     0     0  \n",
      "2        0     0     0     0     0     0     0     0     0  \n",
      "3        0     0     0     0     0     0     0     0     0  \n",
      "4        0     0     0     0     0     0     0     0     0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3355     0     0     0     0     0     0     0     0     0  \n",
      "3356     0     0     0     0     0     0     0     0     0  \n",
      "3357     0     0     0     0     0     0     0     0     0  \n",
      "3358     0     0     0     0     0     0     0     0     0  \n",
      "3359     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[3360 rows x 1024 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "#header = 0 because\n",
    "#this creates a pandas dataframe (basically a table)\n",
    "train_data = pd.read_csv(DIRECTORY +  '/csvTrainImages 13440x1024.csv', header = None)\n",
    "train_label = pd.read_csv(DIRECTORY + '/csvTrainLabel 13440x1.csv', header = None)\n",
    "\n",
    "test_label = pd.read_csv(DIRECTORY +  '/csvTestLabel 3360x1.csv', header = None)\n",
    "\n",
    "\n",
    "#what happens if we take off header = none ?\n",
    "#Row number(s) to use as the column names, and the start of the data. Default behavior is to infer the column names: if no \n",
    "#names are passed the behavior is identical to header=0 and column names are inferred from the first line of the file, \n",
    "#if column names are passed explicitly then the behavior is identical to header=None.\n",
    "#notice if we do this we have one row less\n",
    "test_data = pd.read_csv(DIRECTORY +   '/csvTestImages 3360x1024.csv')\n",
    "print(test_data)\n",
    "\n",
    "test_data = pd.read_csv(DIRECTORY +   '/csvTestImages 3360x1024.csv', header = None)\n",
    "print(test_data)\n",
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.iloc[:,:].values.astype('float32')\n",
    "train_label = train_label.iloc[:,:].values.astype('int32')-1\n",
    "test_data = test_data.iloc[:,:].values.astype('float32')\n",
    "test_label = test_label.iloc[:,:].values.astype('int32')-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = du.to_categorical(train_label,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/255\n",
    "test_data = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape([-1, 32, 32, 1])\n",
    "test_data = test_data.reshape([-1, 32, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, mean1 = du.featurewise_zero_center(train_data)\n",
    "#test_data, mean2 = du.featurewise_zero_center(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recognizer = Sequential()\n",
    "#for any kind of deep learning we use the sequential model in keras then \n",
    "#add layers to it\n",
    "recognizer.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (32,32,1)))\n",
    "#the first 2 dimensional convolusion layer will have 32 filters. filters or kernels are \n",
    "#what we use to extract features. in this case they are of size 5x5 (kernel size)\n",
    "#in the first layer it is necessary to specify the shape so for our case its a\n",
    "#32x32 pixel image and since it's black and white then it has only one dimension\n",
    "#if it was colored then we would have (32,32,3)\n",
    "#activation='relu' this is rectified linear unit. the output filters or convolced layers\n",
    "#might contain some negative values so we apply the rectifier function (or other functions)\n",
    "recognizer.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "recognizer.add(MaxPool2D(pool_size=(2,2)))\n",
    "recognizer.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "recognizer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "recognizer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "recognizer.add(MaxPool2D(pool_size=(2,2), strides=(1,1)))\n",
    "recognizer.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "recognizer.add(Flatten())\n",
    "recognizer.add(Dense(units = 256, input_dim = 1024, activation = 'relu'))\n",
    "recognizer.add(Dense(units = 256, activation = \"relu\"))\n",
    "recognizer.add(Dropout(0.5))\n",
    "recognizer.add(Dense(28, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               3686656   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 3,824,636\n",
      "Trainable params: 3,824,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "recognizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rassa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:1240: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "134/134 - 32s - loss: 2.4577 - acc: 0.2583\n",
      "Epoch 2/30\n",
      "134/134 - 30s - loss: 1.3077 - acc: 0.5576\n",
      "Epoch 3/30\n",
      "134/134 - 31s - loss: 0.8862 - acc: 0.6986\n",
      "Epoch 4/30\n",
      "134/134 - 32s - loss: 0.6584 - acc: 0.7795\n",
      "Epoch 5/30\n",
      "134/134 - 34s - loss: 0.5078 - acc: 0.8329\n",
      "Epoch 6/30\n",
      "134/134 - 34s - loss: 0.4265 - acc: 0.8597\n",
      "Epoch 7/30\n",
      "134/134 - 33s - loss: 0.3631 - acc: 0.8835\n",
      "Epoch 8/30\n",
      "134/134 - 35s - loss: 0.3073 - acc: 0.9044\n",
      "Epoch 9/30\n",
      "134/134 - 33s - loss: 0.2730 - acc: 0.9157\n",
      "Epoch 10/30\n",
      "134/134 - 33s - loss: 0.2448 - acc: 0.9229\n",
      "Epoch 11/30\n",
      "134/134 - 34s - loss: 0.2252 - acc: 0.9262\n",
      "Epoch 12/30\n",
      "134/134 - 33s - loss: 0.2085 - acc: 0.9330\n",
      "Epoch 13/30\n",
      "134/134 - 33s - loss: 0.1890 - acc: 0.9407\n",
      "Epoch 14/30\n",
      "134/134 - 33s - loss: 0.1857 - acc: 0.9410\n",
      "Epoch 15/30\n",
      "134/134 - 32s - loss: 0.1759 - acc: 0.9454\n",
      "Epoch 16/30\n",
      "134/134 - 32s - loss: 0.1638 - acc: 0.9494\n",
      "Epoch 17/30\n",
      "134/134 - 32s - loss: 0.1559 - acc: 0.9534\n",
      "Epoch 18/30\n",
      "134/134 - 33s - loss: 0.1576 - acc: 0.9537\n",
      "Epoch 19/30\n",
      "134/134 - 32s - loss: 0.1469 - acc: 0.9571\n",
      "Epoch 20/30\n",
      "134/134 - 33s - loss: 0.1384 - acc: 0.9591\n",
      "Epoch 21/30\n",
      "134/134 - 33s - loss: 0.1435 - acc: 0.9582\n",
      "Epoch 22/30\n",
      "134/134 - 33s - loss: 0.1404 - acc: 0.9581\n",
      "Epoch 23/30\n",
      "134/134 - 33s - loss: 0.1376 - acc: 0.9604\n",
      "Epoch 24/30\n",
      "134/134 - 33s - loss: 0.1337 - acc: 0.9602\n",
      "Epoch 25/30\n",
      "134/134 - 34s - loss: 0.1293 - acc: 0.9626\n",
      "Epoch 26/30\n",
      "134/134 - 33s - loss: 0.1305 - acc: 0.9617\n",
      "Epoch 27/30\n",
      "134/134 - 33s - loss: 0.1195 - acc: 0.9654\n",
      "Epoch 28/30\n",
      "134/134 - 33s - loss: 0.1282 - acc: 0.9627\n",
      "Epoch 29/30\n",
      "134/134 - 33s - loss: 0.1197 - acc: 0.9654\n",
      "Epoch 30/30\n",
      "134/134 - 34s - loss: 0.1149 - acc: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2772f2596d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer.fit_generator(datagen.flow(train_data,train_label, batch_size=100),\n",
    "                             epochs = 30, verbose = 2, steps_per_epoch=train_data.shape[0] // 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rassa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "predictions = recognizer.predict(test_data)\n",
    "predictions = np.argmax(predictions,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(cm[i][i] for i in range(28)) / test_label.shape[0]\n",
    "print(\"accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 119   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 118   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   5 112   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   3 117   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2 117   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 108   0   9   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0   0   0   2   0]\n",
      " [  0   0   0   0   0   0   0   3 111   0   3   0   0   0   0   0   1   1\n",
      "    0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 119   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   3   4 113   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 120   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1 118   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0 119   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   3 115   0   0   0\n",
      "    0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 120   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4 116   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 119\n",
      "    0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "  119   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 119   1   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   4 114   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0 119   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 120   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 117   0   1   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   1   0   0 117   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0 117   2   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1 118   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0   0 119]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
